from tree import *
import os
import numpy as np
import time
import matplotlib.pyplot as plt

class CkyViterbi(object):
    def __init__(self,train_file,dev_file):
        self.grammar = {}
        self.sorted_rules = []
        self.non_terms = []
        self.term_lookup = {}
        self.back = []
        self.vocabulary = []
        self.parses = []
        self.train_file = train_file
        self.dev_file = dev_file
    def main(self):
        self.read_training()    
        unique_rules = self.convert_probs()
        self.prep_syms()
        self.parse_dev()
    def prep_syms(self):

        self.non_terms = set(self.non_terms)
        self.non_terms = sorted(self.non_terms)
        for i, term in enumerate(self.non_terms):
            self.term_lookup[term ] = i 
        self.vocabulary = set(self.vocabulary)

    def parse_dev(self):
        sentence_lengths = []
        times = []

        dev_parse = open('./part2/output/dev.parses', 'w')
        print("Output for first 5 lines of dev file:")
        for i,line in enumerate(self.dev_file):
            line = line.rstrip()
            line = line.split()
   
            for j,word in enumerate(line):
                if word not in self.vocabulary:
                    line[j] = '<unk>' 
            start_time = time.time()
            parse,prob = self.cky_parse( line )
            tot_time = time.time() - start_time
            times.append(np.log(tot_time))
            sentence_lengths.append(np.log(len(line)))
            dev_parse.write(parse)
            dev_parse.write('\n')
            
            if i < 5:
                print("Line " + str(i) + '\n' + "parse: \n" + parse + "\nLog prob: " + str(prob))

        self.plot(sentence_lengths, times)

    def plot(self,x,y):
        x = np.array(x)
        y = np.array(y)
        plt.scatter(x,y)
        plt.show()
        weights = np.polyfit(x,y,1)
        print("The best fit for this equation = " + str(round(weights[0],3)) + " log(x) " +  str(round(weights[1],3))   )

    def cky_parse(self,line):
      
        # build matrix n by n by X
        best = []
        back = []

        sen_length = len(line)
        neg_inf = -1 * np.inf
        if len(line) == 0:
            return "",""
        # fill best and back matricies
        for i in range(0,sen_length):
            best.append([0]*(sen_length+1))  
            back.append([0] *( sen_length+1)) 
        for i in range(0,sen_length):
            for j in range(0,sen_length+1):
                best[i][j] = [neg_inf] * len(self.non_terms)
                back[i][j] = [0] * len(self.non_terms)

        # populate first diag
        # for each word in sentence
        for i in range(1, sen_length + 1):
            for gen_rule, child_rule_dict in self.grammar.items():
                # if word can be generated by this rule
                if line[i - 1] in child_rule_dict.keys():
                    # prob of this rule
                
                    if child_rule_dict[line[i-1]] > best[i-1][i][self.term_lookup[gen_rule]]:
          
                        best[i-1][i][self.term_lookup[gen_rule]] = child_rule_dict[line[i-1]]
                        back[i-1][i][self.term_lookup[gen_rule]] = [] 
                        back[i-1][i][self.term_lookup[gen_rule]] = [gen_rule, line[i-1],i-1,i]
        for l in range(2, sen_length+1):
            for i in range(0 , sen_length - l+1):
                j = i + l
                for k in range(i+1, j ):
               
                    # iterate through every rule we know
                    for gen_rule, child_rules in self.grammar.items():
                        for child_rule, prob in child_rules.items():
                            # X -> Y Z  - YZ stored as string "Y Z", need to split
                            t_child_rule = child_rule.split()
                            if len(t_child_rule) == 2:
                           
                                prob_p = prob + best[i][k][self.term_lookup[t_child_rule[0]]] + best[k][j][self.term_lookup[t_child_rule[1]]]
                           
                                if prob_p > best[i][j][self.term_lookup[gen_rule]]:
                                    best[i][j][self.term_lookup[gen_rule]] = prob_p
                                    back[i][j][self.term_lookup[gen_rule]] = [gen_rule,t_child_rule[0],t_child_rule[1],i,k,j]
    
        end_rule = back[0][sen_length][self.term_lookup['TOP']]
        # failed parse
        if end_rule == 0:
            return "",""
        else:
            parse = self.print_tree(end_rule, 0,sen_length  , back)
       
            return parse, best[0][sen_length][self.term_lookup['TOP']]

    def print_tree(self, X, i ,j,back):
        ret_string = ""
        ret_string += "("
        ret_string += X[0] + " "
        if len(X) == 4:
            ret_string = "(" + X[0] + " "   + X[1] + ")"
            return ret_string
            
        else:
            y_index = self.term_lookup[X[1]] 
            k = X[4]
 
            ret_string += self.print_tree(back[i][k][y_index],i,X[4], back)
            ret_string += " "
       
            z_index = self.term_lookup[X[2]] 
            ret_string += self.print_tree(back[k][j][z_index],X[4],j,back)
       
            ret_string += ")"
            return ret_string

    def convert_probs(self):
        unique = 0
        for parent_rule, child_rules in self.grammar.items():
            self.non_terms.append(parent_rule)
            unique += len(child_rules.keys())       
            child_sum = sum(child_rules.values())
            for child_rule, count in child_rules.items():
                full_rule = parent_rule + ' -> ' + child_rule
                prob = count / child_sum
                prob = np.log(prob) 
                self.grammar[parent_rule][child_rule] = prob
                self.sorted_rules.append((full_rule, count, prob))
                for term in child_rule.split():
                    self.non_terms.append(term)
        return unique

    def read_training(self):
       
        for line in self.train_file:
            t = Tree.from_str(line)
            self.traverse_tree(t.root)
    def traverse_tree(self,cur_node):
        
        cur_rule = cur_node.label
        if len(cur_node.children) == 2:
            child_rule = cur_node.children[0].label + " " +  cur_node.children[1].label  

        elif len(cur_node.children) == 1:
            child_rule = cur_node.children[0].label
            self.vocabulary.append(cur_node.children[0].label)
        else:
            return "ERR : too many children"
            
        if cur_rule in self.grammar.keys():
            if child_rule in self.grammar[cur_rule].keys():
                self.grammar[cur_rule][child_rule] += 1
            else:
                self.grammar[cur_rule][child_rule] = 1
        else:
            self.grammar[cur_rule] = {}
            self.grammar[cur_rule][child_rule] = 1.
        for node in cur_node.children:
            self.traverse_tree(node)
    def read_parses(self):
        parses = open(os.getcwd() + '/dev.parses.post')
        for line in parses.readlines():
            self.parses.append(line)

if __name__ == "__main__":
    viterbi = CkyViterbi()
    viterbi.main()
